# dictionary-mangler
Creating a mapping between words and their part of speech, starting with Webster's dictionary.

This is part of a project that builds off the Apache Hadoop tutorial http://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html. The rest of the project is available at https://github.com/PatrickHunter/CorpusClassifier. The program PrefixParser searches a text and returns all the strings that are used as a prefix for a given stem. E.g. it will output "C" and "H" when used with the stem "a" and the input text "The Cat in the Hat". The command line argument format for the prefix parser program is: input folder output folder with all inputs in the form of hdfs locations. It also requires that you hardcode the stem. The DefinitionParser program creates a mapping between the words in Webster's (of length 2 or greater) and the parts of speech that they can be. This assumes that it is run with the 1912 edition of Websters and my manually post-processed PrefixParser output (see resources/PartsOfSpeech). From a programmatic perspective, it splits a text that has some all-caps tokens longer than 2 characters and some non-all-caps words into key value pairs of all caps words and all the text between them and the next all-caps word. Then, for each pair, the program searches the value for each word in the secondary input and creates a new key value pair with the original key and the word. The argument format for DefinitionParser is input folder output folder keyword file. Please note that the first two are folders and the third is a file. The input folder can contain any text file(s) that you want analyzed.
My other repository, https://github.com/PatrickHunter/CorpusClassifier, contains code that uses the classification file I generated with this project. As a final note, this program worked as described when I ran it, but its purpose was to teach me Hadoop, and I make no guarantees as to its fitness for any other purpose.

